# -*- coding: utf-8 -*-
"""LSTM-News Machine

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qCaJ_--115VcNjIMSGEoimNfCsHH-N3n
"""

import pandas as pd
import re
import string
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout
import seaborn as sns
import matplotlib.pyplot as plt

# DATA PREPROCESSING
real = pd.read_csv("True.csv", engine='python', on_bad_lines='skip')
fake = pd.read_csv("Fake.csv", engine='python', on_bad_lines='skip')

print(real.shape[0])
print(fake.shape[0])

real["label"] = 0
fake["label"] = 1


df = pd.concat([real, fake], ignore_index=True)


def clean(text):
    text = str(text).lower()
    #remove the URLs
    text = re.sub(r"http\S+", "", text)
    text = text.translate(str.maketrans(string.punctuation, " " * len(string.punctuation)))
    text = re.sub(r"\s+", " ", text).strip()
    return text

df["full_text"] = (df["title"].astype(str) + " " + df["text"].astype(str)).apply(clean)


# TRAIN / TEST SPLIT
X_train, X_test, y_train, y_test = train_test_split(
    df["full_text"],
    df["label"],
    test_size=0.2,
    random_state=42,
    stratify=df["label"]
)

# TOKENIZATION
MAX_WORDS = 30000
MAX_LEN = 300

tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token="<UNK>")
tokenizer.fit_on_texts(X_train)

X_train_seq = tokenizer.texts_to_sequences(X_train)
X_test_seq = tokenizer.texts_to_sequences(X_test)

X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_LEN)
X_test_pad = pad_sequences(X_test_seq, maxlen=MAX_LEN)


# LSTM MODEL
model = Sequential([
    Embedding(MAX_WORDS, 128, input_length=MAX_LEN),

    Bidirectional(LSTM(128, return_sequences=False)),
    Dropout(0.4),

    Dense(128, activation="relu"),
    Dropout(0.3),

    Dense(1, activation="sigmoid")
])

model.compile(
    optimizer="adam",
    loss="binary_crossentropy",
    metrics=["accuracy"]
)


# TRAIN
history = model.fit(
    X_train_pad, y_train,
    epochs=5,
    batch_size=32,
    validation_split=0.2
)

# EVALUATION
y_pred_prob = model.predict(X_test_pad)
y_pred = (y_pred_prob > 0.5).astype(int).reshape(-1)

acc = accuracy_score(y_test, y_pred)
prec = precision_score(y_test, y_pred)
rec = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print("\nAccuracy:", acc)
print("Precision:", prec)
print("Recall:", rec)
print("F1 Score:", f1)


# CONFUSION MATRIX
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6,5))
sns.heatmap(
    cm,
    annot=True,
    fmt="d",
    cmap="Blues",
    xticklabels=["Pred Real", "Pred Fake"],
    yticklabels=["Actual Real", "Actual Fake"]
)
plt.title("Confusion Matrix")
plt.show()
